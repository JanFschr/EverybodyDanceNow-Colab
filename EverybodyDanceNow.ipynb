{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "carolineec/EverybodyDanceNow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4dcBM9NfqP3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae80ed79-6739-448c-f9a0-5ae7d7fbf0ab"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jan 14 04:24:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "3gzMeLqEJi24",
        "outputId": "bfafa8b6-f2de-4b53-fdc1-7948b1010fb4"
      },
      "source": [
        "#@title Install or update EverybodyDanceNow from Github\r\n",
        "\r\n",
        "Mode = \"install\" #@param [\"install\", \"update\"]\r\n",
        "\r\n",
        "from pathlib import Path\r\n",
        "if (Mode == \"install\"):\r\n",
        "  !git clone https://github.com/carolineec/EverybodyDanceNow\r\n",
        "!pip install dominate\r\n",
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\r\n",
        "!pip install tensorflow==1.15.0\r\n",
        "!pip install scipy==1.2.0"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'EverybodyDanceNow'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Total 79 (delta 0), reused 0 (delta 0), pack-reused 79\u001b[K\n",
            "Unpacking objects: 100% (79/79), done.\n",
            "Collecting dominate\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/a8/4354f8122c39e35516a2708746d89db5e339c867abbd8e0179bccee4b7f9/dominate-2.6.0-py2.py3-none-any.whl\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.6.0\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.6.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.6.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (708.0MB)\n",
            "\u001b[K     |████████████████████████████████| 708.0MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.7.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0+cu101) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.6.0+cu101 torchvision-0.7.0+cu101\n",
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 34kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 51.3MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.32.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (51.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=16a3f015c168e7debe9da4ebf3e0a184495409df150206fd83bc75432867d698\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, gast, tensorflow-estimator, keras-applications, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.0\n",
            "    Uninstalling tensorflow-2.4.0:\n",
            "      Successfully uninstalled tensorflow-2.4.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n",
            "Collecting scipy==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/e6/6d4edaceee6a110ecf6f318482f5229792f143e468b34a631f5a0899f56d/scipy-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (26.6MB)\n",
            "\u001b[K     |████████████████████████████████| 26.6MB 122kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.2.0) (1.19.5)\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed scipy-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "hYKj8JYWf6U7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e069b5a-3293-49a3-b85d-f4ae60e21e3a"
      },
      "source": [
        "#@title Import from Drive\r\n",
        "\r\n",
        "Mode = \"EverybodyDanceNow\" #@param [\"EverybodyDanceNow\"]\r\n",
        "Archive_name = \"everybodydancenow.zip\" #@param {type:\"string\"}\r\n",
        "\r\n",
        "#Mount Google Drive as folder\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive', force_remount=True)\r\n",
        "\r\n",
        "def zip_and_copy(path, mode):\r\n",
        "  unzip_cmd=\" -q \"+Archive_name\r\n",
        "  \r\n",
        "  %cd $path\r\n",
        "  copy_cmd = \"/content/drive/My\\ Drive/\"+Archive_name+\" \"+path\r\n",
        "  !cp $copy_cmd\r\n",
        "  !unzip $unzip_cmd    \r\n",
        "  !rm $Archive_name\r\n",
        "\r\n",
        "if Mode == \"EverybodyDanceNow\":\r\n",
        "  zip_and_copy(\"/content\", \"EverybodyDanceNow\")\r\n",
        "elif Mode == \"data_src\":\r\n",
        "  zip_and_copy(\"/content/workspace\", \"data_src\")\r\n",
        "elif Mode == \"data_dst\":\r\n",
        "  zip_and_copy(\"/content/workspace\", \"data_dst\")\r\n",
        "elif Mode == \"data_src aligned\":\r\n",
        "  zip_and_copy(\"/content/workspace/data_src\", \"aligned\")\r\n",
        "elif Mode == \"data_dst aligned\":\r\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"aligned\")\r\n",
        "elif Mode == \"models\":\r\n",
        "  zip_and_copy(\"/content/workspace\", \"model\")\r\n",
        "  \r\n",
        "print(\"Done!\")\r\n",
        "\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJwbYAjBfem0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1af7cdb-adbd-4e84-f001-9766b92ffc9a"
      },
      "source": [
        "cd EverybodyDanceNow"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/EverybodyDanceNow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5Ymz4K_dz6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47eb7423-83df-44a1-cdab-a439cc10ac9d"
      },
      "source": [
        "# train a model at 512x256 resolution\r\n",
        "!python train_fullts.py \\\r\n",
        "--name MY_MODEL_NAME_global \\\r\n",
        "--dataroot MY_TRAINING_DATASET \\\r\n",
        "--checkpoints_dir WHERE_TO_SAVE_CHECKPOINTS \\\r\n",
        "--loadSize 512 \\\r\n",
        "--no_instance \\\r\n",
        "--no_flip \\\r\n",
        "--tf_log \\\r\n",
        "--label_nc 6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "batchSize: 1\n",
            "beta1: 0.5\n",
            "checkpoints_dir: WHERE_TO_SAVE_CHECKPOINTS\n",
            "continue_train: False\n",
            "dataroot: MY_TRAINING_DATASET\n",
            "debug: False\n",
            "display_freq: 100\n",
            "display_winsize: 512\n",
            "faceGtype: unet\n",
            "face_discrim: False\n",
            "face_generator: False\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "gestures: False\n",
            "gpu_ids: [0]\n",
            "instance_feat: False\n",
            "isTrain: True\n",
            "label_feat: False\n",
            "label_nc: 6\n",
            "lambda_A: 10.0\n",
            "lambda_F: 1.0\n",
            "lambda_feat: 10.0\n",
            "loadSize: 512\n",
            "load_features: False\n",
            "load_pretrain: \n",
            "lr: 0.0002\n",
            "max_dataset_size: inf\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_layers_D: 3\n",
            "n_layers_D_face: 3\n",
            "n_local_enhancers: 1\n",
            "name: MY_MODEL_NAME_global\n",
            "ndf: 64\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter: 100\n",
            "niter_decay: 100\n",
            "niter_fix_global: 0\n",
            "niter_fix_main: 0\n",
            "no_flip: True\n",
            "no_ganFeat_loss: False\n",
            "no_html: False\n",
            "no_instance: True\n",
            "no_lsgan: False\n",
            "no_vgg_loss: False\n",
            "norm: instance\n",
            "num_D: 2\n",
            "output_nc: 3\n",
            "phase: train\n",
            "pool_size: 0\n",
            "print_freq: 100\n",
            "resize_or_crop: scale_width\n",
            "save_epoch_freq: 10\n",
            "save_latest_freq: 1000\n",
            "serial_batches: False\n",
            "tf_log: True\n",
            "use_dropout: False\n",
            "use_l1: False\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "#training images = 3\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(6, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "MultiscaleDiscriminator(\n",
            "  (scale0_layer0): Sequential(\n",
            "    (0): Conv2d(12, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (scale1_layer0): Sequential(\n",
            "    (0): Conv2d(12, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
            ")\n",
            "---------- Networks initialized -------------\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100% 548M/548M [00:07<00:00, 77.0MB/s]\n",
            "model [Pix2PixHDModel] was created\n",
            "WARNING:tensorflow:From /content/EverybodyDanceNow/util/visualizer.py:26: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "create web directory WHERE_TO_SAVE_CHECKPOINTS/MY_MODEL_NAME_global/web...\n",
            "End of epoch 1 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 2 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 3 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 4 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 5 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 6 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 7 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 8 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 9 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 10 / 200 \t Time Taken: 1 sec\n",
            "saving the model at the end of epoch 10, iters 30\n",
            "End of epoch 11 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 12 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 13 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 14 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 15 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 16 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 17 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 18 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 19 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 20 / 200 \t Time Taken: 1 sec\n",
            "saving the model at the end of epoch 20, iters 60\n",
            "End of epoch 21 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 22 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 23 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 24 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 25 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 26 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 27 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 28 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 29 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 30 / 200 \t Time Taken: 1 sec\n",
            "saving the model at the end of epoch 30, iters 90\n",
            "End of epoch 31 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 32 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 33 / 200 \t Time Taken: 1 sec\n",
            "(epoch: 34, iters: 1, time: 0.685) G_GAN: 1.110 G_GAN_Feat: 5.138 G_VGG: 3.885 D_real: 0.471 D_fake: 0.622 \n",
            "WARNING:tensorflow:From /content/EverybodyDanceNow/util/visualizer.py:100: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "End of epoch 34 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 35 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 36 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 37 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 38 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 39 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 40 / 200 \t Time Taken: 1 sec\n",
            "saving the model at the end of epoch 40, iters 120\n",
            "End of epoch 41 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 42 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 43 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 44 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 45 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 46 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 47 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 48 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 49 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 50 / 200 \t Time Taken: 1 sec\n",
            "saving the model at the end of epoch 50, iters 150\n",
            "End of epoch 51 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 52 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 53 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 54 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 55 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 56 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 57 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 58 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 59 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 60 / 200 \t Time Taken: 1 sec\n",
            "saving the model at the end of epoch 60, iters 180\n",
            "End of epoch 61 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 62 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 63 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 64 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 65 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 66 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 67 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 68 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 69 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 70 / 200 \t Time Taken: 1 sec\n",
            "saving the model at the end of epoch 70, iters 210\n",
            "End of epoch 71 / 200 \t Time Taken: 2 sec\n",
            "End of epoch 72 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 73 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 74 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 75 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 76 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 77 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 78 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 79 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 80 / 200 \t Time Taken: 1 sec\n",
            "saving the model at the end of epoch 80, iters 240\n",
            "End of epoch 81 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 82 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 83 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 84 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 85 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 86 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 87 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 88 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 89 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 90 / 200 \t Time Taken: 1 sec\n",
            "saving the model at the end of epoch 90, iters 270\n",
            "End of epoch 91 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 92 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 93 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 94 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 95 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 96 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 97 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 98 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 99 / 200 \t Time Taken: 1 sec\n",
            "End of epoch 100 / 200 \t Time Taken: 1 sec\n",
            "saving the model at the end of epoch 100, iters 300\n",
            "End of epoch 101 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000200 -> 0.000198\n",
            "End of epoch 102 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000198 -> 0.000196\n",
            "End of epoch 103 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000196 -> 0.000194\n",
            "End of epoch 104 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000194 -> 0.000192\n",
            "End of epoch 105 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000192 -> 0.000190\n",
            "End of epoch 106 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000190 -> 0.000188\n",
            "End of epoch 107 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000188 -> 0.000186\n",
            "End of epoch 108 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000186 -> 0.000184\n",
            "End of epoch 109 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000184 -> 0.000182\n",
            "End of epoch 110 / 200 \t Time Taken: 1 sec\n",
            "saving the model at the end of epoch 110, iters 330\n",
            "update learning rate: 0.000182 -> 0.000180\n",
            "End of epoch 111 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000180 -> 0.000178\n",
            "End of epoch 112 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000178 -> 0.000176\n",
            "End of epoch 113 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000176 -> 0.000174\n",
            "End of epoch 114 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000174 -> 0.000172\n",
            "End of epoch 115 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000172 -> 0.000170\n",
            "End of epoch 116 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000170 -> 0.000168\n",
            "End of epoch 117 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000168 -> 0.000166\n",
            "End of epoch 118 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000166 -> 0.000164\n",
            "End of epoch 119 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000164 -> 0.000162\n",
            "End of epoch 120 / 200 \t Time Taken: 1 sec\n",
            "saving the model at the end of epoch 120, iters 360\n",
            "update learning rate: 0.000162 -> 0.000160\n",
            "End of epoch 121 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000160 -> 0.000158\n",
            "End of epoch 122 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000158 -> 0.000156\n",
            "End of epoch 123 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000156 -> 0.000154\n",
            "End of epoch 124 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000154 -> 0.000152\n",
            "End of epoch 125 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000152 -> 0.000150\n",
            "End of epoch 126 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000150 -> 0.000148\n",
            "End of epoch 127 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000148 -> 0.000146\n",
            "End of epoch 128 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000146 -> 0.000144\n",
            "End of epoch 129 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000144 -> 0.000142\n",
            "End of epoch 130 / 200 \t Time Taken: 1 sec\n",
            "saving the model at the end of epoch 130, iters 390\n",
            "update learning rate: 0.000142 -> 0.000140\n",
            "End of epoch 131 / 200 \t Time Taken: 4 sec\n",
            "update learning rate: 0.000140 -> 0.000138\n",
            "End of epoch 132 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000138 -> 0.000136\n",
            "End of epoch 133 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000136 -> 0.000134\n",
            "(epoch: 134, iters: 1, time: 0.700) G_GAN: 0.803 G_GAN_Feat: 1.479 G_VGG: 1.521 D_real: 0.461 D_fake: 0.339 \n",
            "End of epoch 134 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000134 -> 0.000132\n",
            "End of epoch 135 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000132 -> 0.000130\n",
            "End of epoch 136 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000130 -> 0.000128\n",
            "End of epoch 137 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000128 -> 0.000126\n",
            "End of epoch 138 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000126 -> 0.000124\n",
            "End of epoch 139 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000124 -> 0.000122\n",
            "End of epoch 140 / 200 \t Time Taken: 1 sec\n",
            "saving the model at the end of epoch 140, iters 420\n",
            "update learning rate: 0.000122 -> 0.000120\n",
            "End of epoch 141 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000120 -> 0.000118\n",
            "End of epoch 142 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000118 -> 0.000116\n",
            "End of epoch 143 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000116 -> 0.000114\n",
            "End of epoch 144 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000114 -> 0.000112\n",
            "End of epoch 145 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000112 -> 0.000110\n",
            "End of epoch 146 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000110 -> 0.000108\n",
            "End of epoch 147 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000108 -> 0.000106\n",
            "End of epoch 148 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000106 -> 0.000104\n",
            "End of epoch 149 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000104 -> 0.000102\n",
            "End of epoch 150 / 200 \t Time Taken: 1 sec\n",
            "saving the model at the end of epoch 150, iters 450\n",
            "update learning rate: 0.000102 -> 0.000100\n",
            "End of epoch 151 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000100 -> 0.000098\n",
            "End of epoch 152 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000098 -> 0.000096\n",
            "End of epoch 153 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000096 -> 0.000094\n",
            "End of epoch 154 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000094 -> 0.000092\n",
            "End of epoch 155 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000092 -> 0.000090\n",
            "End of epoch 156 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000090 -> 0.000088\n",
            "End of epoch 157 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000088 -> 0.000086\n",
            "End of epoch 158 / 200 \t Time Taken: 1 sec\n",
            "update learning rate: 0.000086 -> 0.000084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxX6FUvMd6HP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b92c1bce-dc2c-41ac-f270-71610c178a63"
      },
      "source": [
        "# train a model at 1024x512 resolution\r\n",
        "!python train_fullts.py \\\r\n",
        "--name MY_MODEL_NAME_local \\\r\n",
        "--dataroot MY_TRAINING_DATASET \\\r\n",
        "--checkpoints_dir WHERE_TO_SAVE_CHECKPOINTS \\\r\n",
        "--load_pretrain MY_MODEL_NAME_global \\\r\n",
        "--netG local \\\r\n",
        "--ngf 32 \\\r\n",
        "--num_D 3 \\\r\n",
        "--resize_or_crop none \\\r\n",
        "--no_instance \\\r\n",
        "--no_flip \\\r\n",
        "--tf_log \\\r\n",
        "--label_nc 6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "batchSize: 1\n",
            "beta1: 0.5\n",
            "checkpoints_dir: WHERE_TO_SAVE_CHECKPOINTS\n",
            "continue_train: False\n",
            "dataroot: MY_TRAINING_DATASET\n",
            "debug: False\n",
            "display_freq: 100\n",
            "display_winsize: 512\n",
            "faceGtype: unet\n",
            "face_discrim: False\n",
            "face_generator: False\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "gestures: False\n",
            "gpu_ids: [0]\n",
            "instance_feat: False\n",
            "isTrain: True\n",
            "label_feat: False\n",
            "label_nc: 6\n",
            "lambda_A: 10.0\n",
            "lambda_F: 1.0\n",
            "lambda_feat: 10.0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "load_pretrain: MY_MODEL_NAME_global\n",
            "lr: 0.0002\n",
            "max_dataset_size: inf\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_layers_D: 3\n",
            "n_layers_D_face: 3\n",
            "n_local_enhancers: 1\n",
            "name: MY_MODEL_NAME_local\n",
            "ndf: 64\n",
            "nef: 16\n",
            "netG: local\n",
            "ngf: 32\n",
            "niter: 100\n",
            "niter_decay: 100\n",
            "niter_fix_global: 0\n",
            "niter_fix_main: 0\n",
            "no_flip: True\n",
            "no_ganFeat_loss: False\n",
            "no_html: False\n",
            "no_instance: True\n",
            "no_lsgan: False\n",
            "no_vgg_loss: False\n",
            "norm: instance\n",
            "num_D: 3\n",
            "output_nc: 3\n",
            "phase: train\n",
            "pool_size: 0\n",
            "print_freq: 100\n",
            "resize_or_crop: none\n",
            "save_epoch_freq: 10\n",
            "save_latest_freq: 1000\n",
            "serial_batches: False\n",
            "tf_log: True\n",
            "use_dropout: False\n",
            "use_l1: False\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "#training images = 3\n",
            "LocalEnhancer(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(6, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "  )\n",
            "  (model1_1): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(6, 32, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "  )\n",
            "  (model1_2): Sequential(\n",
            "    (0): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (1): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (2): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (3): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (4): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (7): Conv2d(32, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (8): Tanh()\n",
            "  )\n",
            "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
            ")\n",
            "MultiscaleDiscriminator(\n",
            "  (scale0_layer0): Sequential(\n",
            "    (0): Conv2d(12, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (scale1_layer0): Sequential(\n",
            "    (0): Conv2d(12, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (scale2_layer0): Sequential(\n",
            "    (0): Conv2d(12, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale2_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale2_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale2_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale2_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
            ")\n",
            "---------- Networks initialized -------------\n",
            "Pretrained network G has fewer layers; The following are not initialized:\n",
            "['model1_1', 'model1_2']\n",
            "Pretrained network D has fewer layers; The following are not initialized:\n",
            "['scale2_layer0', 'scale2_layer1', 'scale2_layer2', 'scale2_layer3', 'scale2_layer4']\n",
            "model [Pix2PixHDModel] was created\n",
            "WARNING:tensorflow:From /content/EverybodyDanceNow/util/visualizer.py:26: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "create web directory WHERE_TO_SAVE_CHECKPOINTS/MY_MODEL_NAME_local/web...\n",
            "End of epoch 1 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 2 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 3 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 4 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 5 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 6 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 7 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 8 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 9 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 10 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 10, iters 30\n",
            "End of epoch 11 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 12 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 13 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 14 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 15 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 16 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 17 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 18 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 19 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 20 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 20, iters 60\n",
            "End of epoch 21 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 22 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 23 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 24 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 25 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 26 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 27 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 28 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 29 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 30 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 30, iters 90\n",
            "End of epoch 31 / 200 \t Time Taken: 4 sec\n",
            "End of epoch 32 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 33 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 34 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 35 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 36 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 37 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 38 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 39 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 40 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 40, iters 120\n",
            "End of epoch 41 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 42 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 43 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 44 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 45 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 46 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 47 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 48 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 49 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 50 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 50, iters 150\n",
            "End of epoch 51 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 52 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 53 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 54 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 55 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 56 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 57 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 58 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 59 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 60 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 60, iters 180\n",
            "End of epoch 61 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 62 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 63 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 64 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 65 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 66 / 200 \t Time Taken: 3 sec\n",
            "(epoch: 67, iters: 2, time: 1.955) G_GAN: 1.342 G_GAN_Feat: 2.413 G_VGG: 3.888 D_real: 0.869 D_fake: 0.629 \n",
            "WARNING:tensorflow:From /content/EverybodyDanceNow/util/visualizer.py:100: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "End of epoch 67 / 200 \t Time Taken: 4 sec\n",
            "End of epoch 68 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 69 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 70 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 70, iters 210\n",
            "End of epoch 71 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 72 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 73 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 74 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 75 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 76 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 77 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 78 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 79 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 80 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 80, iters 240\n",
            "End of epoch 81 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 82 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 83 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 84 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 85 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 86 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 87 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 88 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 89 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 90 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 90, iters 270\n",
            "End of epoch 91 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 92 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 93 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 94 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 95 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 96 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 97 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 98 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 99 / 200 \t Time Taken: 3 sec\n",
            "(epoch: 100, iters: 3, time: 1.936) G_GAN: 0.720 G_GAN_Feat: 1.477 G_VGG: 3.192 D_real: 0.663 D_fake: 0.862 \n",
            "End of epoch 100 / 200 \t Time Taken: 4 sec\n",
            "saving the model at the end of epoch 100, iters 300\n",
            "End of epoch 101 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000200 -> 0.000198\n",
            "End of epoch 102 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000198 -> 0.000196\n",
            "End of epoch 103 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000196 -> 0.000194\n",
            "End of epoch 104 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000194 -> 0.000192\n",
            "End of epoch 105 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000192 -> 0.000190\n",
            "End of epoch 106 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000190 -> 0.000188\n",
            "End of epoch 107 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000188 -> 0.000186\n",
            "End of epoch 108 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000186 -> 0.000184\n",
            "End of epoch 109 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000184 -> 0.000182\n",
            "End of epoch 110 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 110, iters 330\n",
            "update learning rate: 0.000182 -> 0.000180\n",
            "End of epoch 111 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000180 -> 0.000178\n",
            "End of epoch 112 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000178 -> 0.000176\n",
            "End of epoch 113 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000176 -> 0.000174\n",
            "End of epoch 114 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000174 -> 0.000172\n",
            "End of epoch 115 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000172 -> 0.000170\n",
            "End of epoch 116 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000170 -> 0.000168\n",
            "End of epoch 117 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000168 -> 0.000166\n",
            "End of epoch 118 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000166 -> 0.000164\n",
            "End of epoch 119 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000164 -> 0.000162\n",
            "End of epoch 120 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 120, iters 360\n",
            "update learning rate: 0.000162 -> 0.000160\n",
            "End of epoch 121 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000160 -> 0.000158\n",
            "End of epoch 122 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000158 -> 0.000156\n",
            "End of epoch 123 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000156 -> 0.000154\n",
            "End of epoch 124 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000154 -> 0.000152\n",
            "End of epoch 125 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000152 -> 0.000150\n",
            "End of epoch 126 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000150 -> 0.000148\n",
            "End of epoch 127 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000148 -> 0.000146\n",
            "End of epoch 128 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000146 -> 0.000144\n",
            "End of epoch 129 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000144 -> 0.000142\n",
            "End of epoch 130 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 130, iters 390\n",
            "update learning rate: 0.000142 -> 0.000140\n",
            "End of epoch 131 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000140 -> 0.000138\n",
            "End of epoch 132 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000138 -> 0.000136\n",
            "End of epoch 133 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000136 -> 0.000134\n",
            "(epoch: 134, iters: 1, time: 1.776) G_GAN: 0.950 G_GAN_Feat: 1.126 G_VGG: 2.769 D_real: 0.743 D_fake: 0.630 \n",
            "End of epoch 134 / 200 \t Time Taken: 4 sec\n",
            "update learning rate: 0.000134 -> 0.000132\n",
            "End of epoch 135 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000132 -> 0.000130\n",
            "End of epoch 136 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000130 -> 0.000128\n",
            "End of epoch 137 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000128 -> 0.000126\n",
            "End of epoch 138 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000126 -> 0.000124\n",
            "End of epoch 139 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000124 -> 0.000122\n",
            "End of epoch 140 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 140, iters 420\n",
            "update learning rate: 0.000122 -> 0.000120\n",
            "End of epoch 141 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000120 -> 0.000118\n",
            "End of epoch 142 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000118 -> 0.000116\n",
            "End of epoch 143 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000116 -> 0.000114\n",
            "End of epoch 144 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000114 -> 0.000112\n",
            "End of epoch 145 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000112 -> 0.000110\n",
            "End of epoch 146 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000110 -> 0.000108\n",
            "End of epoch 147 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000108 -> 0.000106\n",
            "End of epoch 148 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000106 -> 0.000104\n",
            "End of epoch 149 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000104 -> 0.000102\n",
            "End of epoch 150 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 150, iters 450\n",
            "update learning rate: 0.000102 -> 0.000100\n",
            "End of epoch 151 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000100 -> 0.000098\n",
            "End of epoch 152 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000098 -> 0.000096\n",
            "End of epoch 153 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000096 -> 0.000094\n",
            "End of epoch 154 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000094 -> 0.000092\n",
            "End of epoch 155 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000092 -> 0.000090\n",
            "End of epoch 156 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000090 -> 0.000088\n",
            "End of epoch 157 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000088 -> 0.000086\n",
            "End of epoch 158 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000086 -> 0.000084\n",
            "End of epoch 159 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000084 -> 0.000082\n",
            "End of epoch 160 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 160, iters 480\n",
            "update learning rate: 0.000082 -> 0.000080\n",
            "End of epoch 161 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000080 -> 0.000078\n",
            "End of epoch 162 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000078 -> 0.000076\n",
            "End of epoch 163 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000076 -> 0.000074\n",
            "End of epoch 164 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000074 -> 0.000072\n",
            "End of epoch 165 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000072 -> 0.000070\n",
            "End of epoch 166 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000070 -> 0.000068\n",
            "(epoch: 167, iters: 2, time: 1.956) G_GAN: 0.759 G_GAN_Feat: 1.057 G_VGG: 2.371 D_real: 0.711 D_fake: 0.767 \n",
            "End of epoch 167 / 200 \t Time Taken: 4 sec\n",
            "update learning rate: 0.000068 -> 0.000066\n",
            "End of epoch 168 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000066 -> 0.000064\n",
            "End of epoch 169 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000064 -> 0.000062\n",
            "End of epoch 170 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 170, iters 510\n",
            "update learning rate: 0.000062 -> 0.000060\n",
            "End of epoch 171 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000060 -> 0.000058\n",
            "End of epoch 172 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000058 -> 0.000056\n",
            "End of epoch 173 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000056 -> 0.000054\n",
            "End of epoch 174 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000054 -> 0.000052\n",
            "End of epoch 175 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000052 -> 0.000050\n",
            "End of epoch 176 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000050 -> 0.000048\n",
            "End of epoch 177 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000048 -> 0.000046\n",
            "End of epoch 178 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000046 -> 0.000044\n",
            "End of epoch 179 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000044 -> 0.000042\n",
            "End of epoch 180 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 180, iters 540\n",
            "update learning rate: 0.000042 -> 0.000040\n",
            "End of epoch 181 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000040 -> 0.000038\n",
            "End of epoch 182 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000038 -> 0.000036\n",
            "End of epoch 183 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000036 -> 0.000034\n",
            "End of epoch 184 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000034 -> 0.000032\n",
            "End of epoch 185 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000032 -> 0.000030\n",
            "End of epoch 186 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000030 -> 0.000028\n",
            "End of epoch 187 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000028 -> 0.000026\n",
            "End of epoch 188 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000026 -> 0.000024\n",
            "End of epoch 189 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000024 -> 0.000022\n",
            "End of epoch 190 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 190, iters 570\n",
            "update learning rate: 0.000022 -> 0.000020\n",
            "End of epoch 191 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000020 -> 0.000018\n",
            "End of epoch 192 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000018 -> 0.000016\n",
            "End of epoch 193 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000016 -> 0.000014\n",
            "End of epoch 194 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000014 -> 0.000012\n",
            "End of epoch 195 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000012 -> 0.000010\n",
            "End of epoch 196 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000010 -> 0.000008\n",
            "End of epoch 197 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000008 -> 0.000006\n",
            "End of epoch 198 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000006 -> 0.000004\n",
            "End of epoch 199 / 200 \t Time Taken: 3 sec\n",
            "update learning rate: 0.000004 -> 0.000002\n",
            "(epoch: 200, iters: 3, time: 1.936) G_GAN: 0.799 G_GAN_Feat: 0.850 G_VGG: 2.045 D_real: 0.729 D_fake: 0.718 \n",
            "End of epoch 200 / 200 \t Time Taken: 4 sec\n",
            "saving the model at the end of epoch 200, iters 600\n",
            "update learning rate: 0.000002 -> 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVpjdvE4d8Wf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99cea287-8ef2-401e-84ed-338eb5fd4c4e"
      },
      "source": [
        "# train a model specialized to the face region\r\n",
        "!python train_fullts.py \\\r\n",
        "--name MY_MODEL_NAME_face \\\r\n",
        "--dataroot MY_TRAINING_DATASET \\\r\n",
        "--load_pretrain MY_MODEL_NAME_local \\\r\n",
        "--checkpoints_dir WHERE_TO_SAVE_CHECKPOINTS \\\r\n",
        "--face_discrim \\\r\n",
        "--face_generator \\\r\n",
        "--faceGtype global \\\r\n",
        "--niter_fix_main 10 \\\r\n",
        "--netG local \\\r\n",
        "--ngf 32 \\\r\n",
        "--num_D 3 \\\r\n",
        "--resize_or_crop none \\\r\n",
        "--no_instance \\\r\n",
        "--no_flip \\\r\n",
        "--tf_log \\\r\n",
        "--label_nc 6\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "batchSize: 1\n",
            "beta1: 0.5\n",
            "checkpoints_dir: WHERE_TO_SAVE_CHECKPOINTS\n",
            "continue_train: False\n",
            "dataroot: MY_TRAINING_DATASET\n",
            "debug: False\n",
            "display_freq: 100\n",
            "display_winsize: 512\n",
            "faceGtype: global\n",
            "face_discrim: True\n",
            "face_generator: True\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "gestures: False\n",
            "gpu_ids: [0]\n",
            "instance_feat: False\n",
            "isTrain: True\n",
            "label_feat: False\n",
            "label_nc: 6\n",
            "lambda_A: 10.0\n",
            "lambda_F: 1.0\n",
            "lambda_feat: 10.0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "load_pretrain: MY_MODEL_NAME_local\n",
            "lr: 0.0002\n",
            "max_dataset_size: inf\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_layers_D: 3\n",
            "n_layers_D_face: 3\n",
            "n_local_enhancers: 1\n",
            "name: MY_MODEL_NAME_face\n",
            "ndf: 64\n",
            "nef: 16\n",
            "netG: local\n",
            "ngf: 32\n",
            "niter: 100\n",
            "niter_decay: 100\n",
            "niter_fix_global: 0\n",
            "niter_fix_main: 10\n",
            "no_flip: True\n",
            "no_ganFeat_loss: False\n",
            "no_html: False\n",
            "no_instance: True\n",
            "no_lsgan: False\n",
            "no_vgg_loss: False\n",
            "norm: instance\n",
            "num_D: 3\n",
            "output_nc: 3\n",
            "phase: train\n",
            "pool_size: 0\n",
            "print_freq: 100\n",
            "resize_or_crop: none\n",
            "save_epoch_freq: 10\n",
            "save_latest_freq: 1000\n",
            "serial_batches: False\n",
            "tf_log: True\n",
            "use_dropout: False\n",
            "use_l1: False\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "----------- loading face bounding boxes from MY_TRAINING_DATASET/train_facetexts128 ----------\n",
            "#training images = 3\n",
            "LocalEnhancer(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(6, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "  )\n",
            "  (model1_1): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(6, 32, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "  )\n",
            "  (model1_2): Sequential(\n",
            "    (0): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (1): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (2): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (3): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (4): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (7): Conv2d(32, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (8): Tanh()\n",
            "  )\n",
            "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
            ")\n",
            "MultiscaleDiscriminator(\n",
            "  (scale0_layer0): Sequential(\n",
            "    (0): Conv2d(12, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (scale1_layer0): Sequential(\n",
            "    (0): Conv2d(12, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (scale2_layer0): Sequential(\n",
            "    (0): Conv2d(12, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale2_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale2_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale2_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale2_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
            ")\n",
            "NLayerDiscriminator(\n",
            "  (facemodel): Sequential(\n",
            "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            ")\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(6, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (14): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (15): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (19): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (22): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (23): ReLU(inplace=True)\n",
            "    (24): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (25): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (28): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (29): Tanh()\n",
            "  )\n",
            ")\n",
            "---------- Networks initialized -------------\n",
            "MY_MODEL_NAME_local/latest_net_Dface.pth not exists yet!\n",
            "MY_MODEL_NAME_local/latest_net_Gface.pth not exists yet!\n",
            "------------- Only training the face discriminator network (for 10 epochs) ------------\n",
            "model [Pix2PixHDModel] was created\n",
            "WARNING:tensorflow:From /content/EverybodyDanceNow/util/visualizer.py:26: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "create web directory WHERE_TO_SAVE_CHECKPOINTS/MY_MODEL_NAME_face/web...\n",
            "End of epoch 1 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 2 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 3 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 4 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 5 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 6 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 7 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 8 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 9 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 10 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 10, iters 30\n",
            "------------- traing all the discriminators now and not just the face -------------\n",
            "------------ Now also finetuning multiscale discriminator -----------\n",
            "End of epoch 11 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 12 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 13 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 14 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 15 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 16 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 17 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 18 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 19 / 200 \t Time Taken: 3 sec\n",
            "End of epoch 20 / 200 \t Time Taken: 3 sec\n",
            "saving the model at the end of epoch 20, iters 60\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 364, in save\n",
            "    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 477, in _save\n",
            "    zip_file.write_record(name, storage.data_ptr(), num_bytes)\n",
            "OSError: [Errno 28] No space left on device\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"train_fullts.py\", line 138, in <module>\n",
            "    model.module.save(epoch)\n",
            "  File \"/content/EverybodyDanceNow/models/pix2pixHD_model_fullts.py\", line 334, in save\n",
            "    self.save_network(self.netG, 'G', which_epoch, self.gpu_ids)\n",
            "  File \"/content/EverybodyDanceNow/models/base_model.py\", line 47, in save_network\n",
            "    torch.save(network.cpu().state_dict(), save_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 365, in save\n",
            "    return\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/serialization.py\", line 258, in __exit__\n",
            "    self.file_like.write_end_of_file()\n",
            "RuntimeError: [enforce fail at inline_container.cc:262] . unexpected pos 440446080 vs 440445968\n",
            "terminate called after throwing an instance of 'c10::Error'\n",
            "  what():  [enforce fail at inline_container.cc:262] . unexpected pos 440446080 vs 440445968\n",
            "frame #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::string const&, void const*) + 0x47 (0x7ff25f551fd7 in /usr/local/lib/python3.6/dist-packages/torch/lib/libc10.so)\n",
            "frame #1: <unknown function> + 0x228ff30 (0x7ff298836f30 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #2: <unknown function> + 0x228c163 (0x7ff298833163 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #3: caffe2::serialize::PyTorchStreamWriter::writeRecord(std::string const&, void const*, unsigned long, bool) + 0x17b (0x7ff29883810b in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #4: caffe2::serialize::PyTorchStreamWriter::writeEndOfFile() + 0xe1 (0x7ff298838ca1 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #5: caffe2::serialize::PyTorchStreamWriter::~PyTorchStreamWriter() + 0x115 (0x7ff298839495 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #6: <unknown function> + 0x5a35e3 (0x7ff2a71275e3 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\n",
            "frame #7: <unknown function> + 0x273c00 (0x7ff2a6df7c00 in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\n",
            "frame #8: <unknown function> + 0x274e4e (0x7ff2a6df8e4e in /usr/local/lib/python3.6/dist-packages/torch/lib/libtorch_python.so)\n",
            "frame #9: python3() [0x588948]\n",
            "frame #10: python3() [0x5ad418]\n",
            "frame #11: python3() [0x5ad42e]\n",
            "frame #12: python3() [0x5ad42e]\n",
            "frame #13: python3() [0x5ad42e]\n",
            "frame #14: python3() [0x56b4c6]\n",
            "<omitting python frames>\n",
            "frame #20: __libc_start_main + 0xe7 (0x7ff2aaa35bf7 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq-2CKDEeX4e"
      },
      "source": [
        "# test model at 512x256 resolution\r\n",
        "python test_fullts.py \\\r\n",
        "--name MY_MODEL_NAME_global \\\r\n",
        "--dataroot MY_TEST_DATASET \\\r\n",
        "--checkpoints_dir CHECKPOINT_FILE_LOCATION \\\r\n",
        "--results_dir WHERE_TO_SAVE_RESULTS \\\r\n",
        "--loadSize 512 \\\r\n",
        "--no_instance \\\r\n",
        "--how_many 10000 \\\r\n",
        "--label_nc 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeMlp79sIAqb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "dd118171-56b0-4f43-e2f9-d5fe8e849d8b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;34m': timeout during initial read of root folder; for more info: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             'https://research.google.com/colaboratory/faq.html#drive-timeout')\n\u001b[0;32m--> 256\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m       \u001b[0;31m# Not already authorized, so do the authorization dance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrhb_PQLeZul"
      },
      "source": [
        "# test model at 1024x512 resolution\r\n",
        "!python test_fullts.py \\\r\n",
        "--name MY_MODEL_NAME_local \\\r\n",
        "--dataroot MY_TEST_DATASET \\\r\n",
        "--checkpoints_dir CHECKPOINT_FILE_LOCATION \\\r\n",
        "--results_dir WHERE_TO_SAVE_RESULTS \\\r\n",
        "--netG local \\\r\n",
        "--ngf 32 \\\r\n",
        "--resize_or_crop none \\\r\n",
        "--no_instance \\\r\n",
        "--how_many 10000 \\\r\n",
        "--label_nc 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_yUn8mIeb4F"
      },
      "source": [
        "# test model at 1024x512 resolution with face GAN\r\n",
        "!python test_fullts.py \\\r\n",
        "--name MY_MODEL_NAME_face \\\r\n",
        "--dataroot MY_TEST_DATASET \\\r\n",
        "--checkpoints_dir CHECKPOINT_FILE_LOCATION \\\r\n",
        "--results_dir WHERE_TO_SAVE_RESULTS \\\r\n",
        "--face_generator \\\r\n",
        "--faceGtype global \\\r\n",
        "--netG local \\\r\n",
        "--ngf 32 \\\r\n",
        "--resize_or_crop none \\\r\n",
        "--no_instance \\\r\n",
        "--how_many 10000 \\\r\n",
        "--label_nc 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "dNgZS205FMk8",
        "outputId": "62fa4aca-d9ff-4ecd-db5a-2368f607673d"
      },
      "source": [
        "#@title Export to Drive { form-width: \"30%\" }\r\n",
        "Mode = \"EverybodyDanceNow\" #@param [\"EverybodyDanceNow\"]\r\n",
        "Archive_name = \"everybodydancenow.zip\" #@param {type:\"string\"}\r\n",
        "\r\n",
        "#Mount Google Drive as folder\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive', force_remount=True)\r\n",
        "\r\n",
        "def zip_and_copy(path, mode):\r\n",
        "  zip_cmd=\"-r -q \"+Archive_name+\" \"\r\n",
        "  \r\n",
        "  %cd $path\r\n",
        "  zip_cmd+=mode\r\n",
        "  !zip $zip_cmd\r\n",
        "  copy_cmd = \" \"+Archive_name+\"  /content/drive/My\\ Drive/\"\r\n",
        "  !cp $copy_cmd\r\n",
        "  !rm $Archive_name\r\n",
        "\r\n",
        "if Mode == \"EverybodyDanceNow\":\r\n",
        "  zip_and_copy(\"/content\", \"EverybodyDanceNow\", \"MY_MODEL_NAME_global\", \"MY_MODEL_NAME_local\")\r\n",
        "\r\n",
        " \r\n",
        "  \r\n",
        "print(\"Done!\")\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3de120cd7bbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mMode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"EverybodyDanceNow\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mzip_and_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"EverybodyDanceNow\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MY_MODEL_NAME_global\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MY_MODEL_NAME_local\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: zip_and_copy() takes 2 positional arguments but 4 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-cgYMXIg6r6"
      },
      "source": [
        "## **Dataset preparation**"
      ]
    }
  ]
}